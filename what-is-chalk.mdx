---
title: What is Chalk?
metaTitle: What is Chalk?
metaDescription: 'Chalk is the data platform for inference that enables innovative machine learning teams to focus on building the unique products and models that make their business stand out.'
titleHidden: true
hideToc: true
published: true
---

import { DocsHero } from '@/components/home/DocsHero'
import { TemporalCorrectness } from '@/components/home/TemporalCorrectness'
import { highlightedCode as addCachingCode } from '@/samples/features/add_caching.py?highlight=diff-py'
import { IntegrationTypes } from '@/components/home/IntegrationTypes'
import { JupyterNotebook } from '@/components/home/Jupyter'
import { RequestingFeaturesOnline } from '@/components/home/RequestingFeaturesOnline'

import { PyDiffEditor } from '@/components/Editor'

<DocsHero />

Build, deploy, and iterate faster with Chalk — a programmable feature engine that powers low-latency inference, rapid model iteration, and observability across your model lifecycle.
Chalk solves core pain points teams face when building enterprise AI and ML systems:

- deploying and scaling production-grade infrastructure
- authoring feature pipelines in pure Python — No DSLs! No rewrites!
- building training datasets with high throughput batch offline queries and point-in-time correctness
- evaluating LLMs at scale by integrating unstructured inputs into pipelines
- serving fresh features on-the-fly with versioning, branching, and full observability
    - gradually rollout, easily rollback, and feature flag models with version control
    - collaborate across teams with branch-based QA
    - A/B test with real historical production traffic by leveraging Chalk’s feature store

---

## How does Chalk make feature engineering easier?

Define features using Pythonic classes in Chalk — no DSLs required.
Every feature is:
- typed and validated
- versioned and testable
- composable and reusable in both training and online inference

Describe relationships between entities (e.g., users and transactions) with simple type annotations, and Chalk takes care of joins, lineage, and query planning automatically.

```py
import chalk.functions as F
from chalk.features import features
from chalk import  DataFrame, Windowed, windowed, _

@features
class Transaction:
    id: int
    amount: float
    discount_percentage: float
    at: datetime

    # create new features inline with Chalk Expressions
    is_expensive_purchase: bool = _.amount > 100

    # instead of declaring user_id as a string type (user_id: str),
    # reference a feature from another class
    user_id: "User.id"

    # Chalk infers the "User.id" join key, enabling you to reference
    # the User associated with this transaction!
    user: "User"

@features
class User:
    # id, name, email are pulled from underlying data sources like
    # SQL (Postgres, Athena, Glue, Iceberg), Snowflake, Databricks, Kafka streams, etc.
    id: int
    name: str
    email: str

    # computed via a Python resolver, more on this later
    username: str

    # Chalk SDK provides common ML primitives
    name_match: float = F.levenshtein_distance(_.name, _.email)

    # leverages "User.id" type annotation from Transaction class
    # as a join key to create an intermediate DataFrame
    txns: DataFrame[Transaction]

    # reference dataframes to run aggregations
    transaction_count: int = _.txns.count()

    # easily filter dataframes before running an aggregation
    average_discount_percentage: float = _.txns[
        _.amount,
        _.discount_percentage > 0,
    ].mean()

    # run aggregations across time intervals
    total_transaction_amount: Windowed[float] = windowed(
        "1d",
        "7d",
        "30d",
        expression=_.txns[
            _.amount,
            _.at > _.chalk_window,
        ].sum(),
    )
```

Chalk queries allow you to explicitly express the features you want returned:

```shell
chalk query --in user.id=241 --out name_match --out transactions
```

```
Results
https://chalk.ai/environments/{environment}/query-runs/{query_id}
Branch: elvis
Environment: {environment}

 Name                       Hit?  Value
────────────────────────────────────────
 user.name_match        41.0


user.txns

 id    transaction_status  user_id  session_id  item_count  cheapest_line_item_price  most_expensively_valued_product_id  created_at                          updated_at
─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
 17    "failed"            27       16281       2           34                        20364                               "2024-12-06T00:36:07.348750+00:00"  "2024-12-06T19:53:21.575073+00:00"
 18    "failed"            27       16282       1           71.41                     20362                               "2024-11-26T11:29:03.684327+00:00"  "2024-11-27T01:50:03.002378+00:00"
 5440  "pending"           27       16357       1           62.64                     20180                               "2024-11-16T17:29:43.540722+00:00"  null
 67    "cleared"           27       16358       1           86.31                     20179                               "2024-11-28T04:11:31.857431+00:00"  "2024-11-29T04:08:29.746079+00:00"
 68    "cleared"           27       16359       1           138.38                    20178                               "2024-11-11T01:19:53.140456+00:00"  "2024-11-11T11:35:40.673632+00:00"



(5 rows)
```

When running this query, Chalk only fetches exactly the base features needed to return `name_match` and `txns`.

Chalk analyzes type annotations to build a directed acyclic graph (DAG) of feature dependencies.
At inference time, query plans tailored to your input/output schema are generated dynamically by slicing this DAG into sub-graphs.
This ensures that only the features needed are fetched — optimizing for speed, precision, and cost.

Each node in the DAG is a Chalk expression or resolver (SQL / Python):

- An expression e.g. `is_expensive_purchase: bool = _.amount > 100`
- A SQL file that connects to an underlying data store like Athena
- Python resolver i.e. ordinary Python functions (Pandas, httpx, or LLM calls)

Here's an example of a generated query plan:

![Chalk query plan](/img/docs-what_is_chalk-query_plan.png)

### How does Chalk resolve features? What are Chalk resolvers?

Chalk connects directly to your existing infrastructure and underlying data stores (Athena, BigQuery, Postgres, Iceberg catalog, etc.) with [SQL resolvers](https://docs.chalk.ai/docs/sql-resolvers) and to APIs (microservices, 3rd-party clients, LLMs) with [Python resolvers](https://docs.chalk.ai/docs/python-resolvers).
Resolvers make it easy to integrate a wide variety of data sources, join them together, and use them in inference.

Decoupling feature logic from ETL pipelines unlocks

- faster iteration cycles
- on-demand just-in-time inference
- reproducible and testable features (with point-in-time accuracy)

<IntegrationTypes />

### How does Chalk orchestrate and manage features?

Chalk has built-in support for feature engineering workflows — there's no need to manage Airflow or orchestrate complicated streaming flows.
Once you've defined features and resolvers, Chalk orchestrates them into flexible pipelines (slicing the DAG) that make both training and model execution easy.

The `get_username` function below explicitly defines input dependencies through `User.email` and specifies the output feature type as `User.username`:

```py
@online
def get_username(
    # the input type annotation specifies the required feature
    email: User.email,
    # the resulting feature is saved as username unto User class
) -> User.username:
    username = email.split("@")[0]
    if "gmail.com" in email:
        username = username.split("+")[0].replace(".", "")

    return username.lower()
```

Although written in Python, this function compiles into a static Velox expression through Chalk's Symbolic Python Interpreter and executes natively in C++.
This provides Python-first development without sacrificing performance.

```py
lower(
    if_then_else(
        !=(
            strpos(str(email), str(gmail.com)),
            int(0)
        ),
        replace(
            element_at(
                split(
                    element_at(split(str(email), str(@)), int(1)),
                    str(+)
                ),
                int(1)
            ),
            str(.),
            str()
        ),
        element_at(split(str(email), str(@)), int(1))
    )
)
```

We wrote an [engineering blog post on our Symbolic Python interpreter](https://chalk.ai/blog/symbolic-python-interpreter) if you want to learn more!

### How can I cache features in Chalk?

Some data sources, like LLMs or 3rd party APIs, are expensive or slow to call at inference time.
Chalk supports caching features to optimize for latency and cost:

- define cache windows inline with your features
- override staleness at query-time when fresh data is critical
- pre-warm caches and backfill pipelines for performance

Add a caching policy with one line of code in our feature definition:

<PyDiffEditor html={addCachingCode} />


### How do I deploy and query features with Chalk?

After defining pipelines, deploy features to a branch in < 1s with:
Chalk automatically detects and uses your current git branch name without requiring you to explicitly specify it:

```shell
chalk apply --branch
```

Query for features against this branch and perform QA workflows on branch deployments to ensure pipelines perform as expected:

```shell
chalk query --branch --in user.id=47
```

This command returns the user's features from your branch deployment, showing all computed fields for the specified `user.id`.

```
Using '--out=user'
Results
https://chalk.ai/environments/{environment}/query-runs/{query_id}
Branch: elvis
Environment: {environment}

 Name                                             Hit?  Value
─────────────────────────────────────────────────────────────────────────────────────────────────────
 user.average_rating_given                  4.3125
 user.birthday                              "1987-12-28"
 user.created_at                            "2024-08-07T20:54:42.942294+00:00"
 user.email                                 "98178ad58fe8481db74996996d6e8de7@google.ru"
 user.first_name                            "Marseda"
 user.id                                    47
 user.last_name                             "Karkaletsis"
 user.review_count                          32
 user.total_orders_placed                   48
 user.unique_products_inquired_about        203
```

Once validated, promote the deployment to production, which is served at a unique preview URL.

```shell
chalk apply
```

These features are now available for low-latency [online inference](/docs/query-basics) and [offline training](/docs/training-client).
The ability to re-use the same features in both contexts dramatically shortens development time and ensures that feature values from online and offline contexts match.

---

## Why Chalk?

Chalk is the first platform to unify feature and prompt engineering, LLM evals, and real-time inference into a unified platform.
Bridge the gap between experimentation and production with a single system that unifies offline and online inference.
Chalk retrieves and computes dynamically at inference time with an execution engine called [Velox](https://github.com/facebookincubator/velox)--we maintain a fork that’s been heavily optimized for low-latency (< 3 ms).

Unifying online and offline execution enables teams to

- consolidate training and serving into a single version controlled environment
- reduce time-to-production for new models from months to days
- build advanced AI systems (RAG, RecSys, Fraud detection, etc.) without building custom infrastructure

**No DSLs, no rewrites, just ordinary Python**

Define features in Python that are run natively in Rust, C++, or as UDFs — no need to manually port notebooks and code into other languages e.g. Scala.

**See everything, debug anything**

Traditional ML systems often operate as opaque black boxes, especially when transformation logic gets embedded across disparate data pipelines, obscuring the connection between inputs and predictions.
Chalk disrupts this paradigm by bringing comprehensive observability to every aspect of your ML systems; easily

- trace every model feature back to its original data sources with detailed lineage tracking — showing exactly where data came from
- troubleshoot and optimize your ML pipelines with end-to-end tracing that tracks the inputs and outputs of every step in any run
- monitor feature drift, access patterns, and performance metrics in real-time across all your model deployments

Iterate faster and deploy with confidence — knowing exactly how your systems behave at each step of the machine learning lifecycle.

---

## Chalk for MLOps

Let Chalk handle orchestrating, caching, and serving features at scale freeing up you and your team to focus on building models—not plumbing.

Democratize modern software engineering practices, with Chalk

- features are discoverable and auditable across all environments
- experimental changes are isolated to branches and safely promoted via CLI with gradual rollouts
- models are versioned and can be easily rolled-back the same way you would an API

Easily serve features across your entire tech stack with SDKs in Python, JavaScript, Java and more - making inference accessible to any team whether for internal tools or customer-facing applications.

<RequestingFeaturesOnline style={{ height: 328 }} />

With Chalk, MLOps teams confidently deploy and serve low-latency ML systems, benefiting from comprehensive observability while supporting gradual rollouts and seamless rollbacks.

---

## Chalk for AI Engineers

Build enterprise-grade AI applications without stitching together LLMs, prompts, vector DBs, and retrieval logic.

- retrieve real-time context into LLMs
- call chat completion APIs out-of-the-box
- generate embeddings and vectors within pipelines
- run large-scale evaluations using historical traffic
- reuse and manage prompts with [named prompts](/docs/prompts)

```py
# Use structured output to easily incorporate unstructured data in our ML pipelines
class AnalyzedReceiptStruct(BaseModel):
    expense_category: ExpenseCategoryEnum
    business_expense: bool
    loyalty_program: str
    return_policy: int

@features
class Transaction:
    id: int
    merchant_id: Merchant.id
    merchant: Merchant
    receipt: Receipt

    llm: P.PromptResponse = P.completion(
        model="gpt-4o-mini-2024-07-18",
        messages=[P.user_message(
            "””Analyze the following receipt:
            Line items: {{Transaction.receipt.line_items}}
            Merchant: {{Transaction.merchant.name}} {{Transaction.merchant.description}}”””
        )],
        output_structure=AnalyzedReceiptStruct,
    )

@features
class ProductRec:
    user_id: Primary[User.id]
    user: User

    user_vector: Vector = embed(
        input=F.array_join(F.array_agg(
            _.user.products[
                _.name,
                _.type == "liked"
            ]),
            delimiter=" || ",
        ),
        provider="vertexai",
        model="text-embedding-005",
    )

    similar_users: DataFrame[User] = has_many(
      lambda: ProductRec.user_vector.is_near(
            User.liked_products_vector
        )
    )
```

With Chalk, AI engineers easily integrate unstructured data, build context-aware prompts, and run LLM evaluations at scale—all without managing vector databases, embedding providers, and complex retrieval systems.

---

## Chalk for Data Scientists

Test new features, run experiments, and ship production models—all from a Jupyter notebook.

- catch regressions and A/B test features on development branches
- import features from production into Jupyter notebooks with a single line of code
- export features to catalogs like Iceberg for downstream analytics and usage
- trace data lineage all the way down to source tables

```python
from chalk.client import ChalkClient

client = ChalkClient(branch=True)
client.load_features() # load prod features with one line

User.name_exclaimed = _.name + "!" # add new features

chalk_dataset = client.offline_query(
    input={
        User.id: list(range(1000)),
    },
    output={
        User.id,
        User.name,
        User.name_exclaimed,
    },
    recompute_features=True, # A/B test against historical model runs
    dataset_name="fraud_model",
)

df = chalk_dataset.to_pandas() # convert to pandas dataframe

# write to Glue or Iceberg
catalog = GlueCatalog(
    name="aws_glue_catalog",
    aws_region="us-west-2",
    catalog_id="123",
    aws_role_arn="arn:aws:iam::123456789012:role/OurCatalogueAccessRole",
)
chalk_dataset.write_to(destination="database.table_name", catalog=catalog)
```

Chalk evaluates features with point-in-time lookups, guaranteeing evaluation only with data that would have been seen in the past. This means that you can provide labels with different past timestamps to easily get historical features that represent what your application would have retrieved online at those past times.

<TemporalCorrectness />

With Chalk, data scientists easily integrate new data sources, test new features with [point-in-time correctness,](docs/temporal-consistency) and collaborate with Git-like branches and flexible data exports (to data catalogs, Parquet, Iceberg, etc.).

---

## Chalk for Data Engineers

Manage features declaratively without the complexity of orchestrating ETL jobs, feature stores, and offline/online datastores.

- cache expensive computations with configurable staleness
- manage versioning and A/B testing of feature computation
- create complex joins and relationships between data entities
- configure time-window aggregations with flexible materialization options

```python
@features
class User:
    id: int
    domain: str

    # composite keys that can be used as join keys
    workspace_id: str = _.domain + "-" + _.id
    expensive_api_call: str = feature(max_staleness="30d") # cache values

    # maintain different resolvers to A/B test function calls e.g. gemini vs openai
    llm_response: str = feature(version=3)

    # multi-attribute joins
    txns: DataFrame[Transaction]

    count_txns: Windowed[int] = windowed(
        "1d", "365d",
        # see our docs on materialized windowed aggregations
        # https://docs.chalk.ai/docs/materialized_aggregations
        materialization=True,
    )
```

Chalk also integrates natively into your existing data infrastructure by [deploying directly into your virtual private cloud](/docs/architecture) (VPC) providing seamless resource access while maintaining strict security and compliance controls with full data isolation:

    - customizable compute layer enabling the use of different memory stores (Redis, etc.) tailored to access patterns and performance requirements
    - inherit existing security groups, policies, and ACLs
    - co-located resources and full-control over data residency to meet compliance requirements

With Chalk, Data Engineers easily manage features programmatically and maintain production systems without the overhead of configuring YAML, custom scripts, or infrastructure.

---

## A full-stack solution for building and deploying enterprise AI

Chalk gives teams the building blocks to prototype and deploy production AI and ML systems quickly and reliably.
Whether you're delivering hyperpersonalized product recommendations, dynamically reranking search results, or detecting sophisticated fraud patterns, Chalk is the platform for low-latency, real-time ML at scale.
[Schedule a demo](https://chalk.ai/book-demo) to see how Chalk fits with your team!
