---
title: BigQuery
description: Integrate with your BigQuery data warehouse.
published: true
---

---

Chalk has an integration with [BigQuery](https://cloud.google.com/bigquery)
that makes it easy to read queries and tables into your feature store.

## Authorization

To use [BigQuery](https://cloud.google.com/bigquery)
in your resolvers, you first need to add the
[Chalk GCP integration](/docs/gcp) to the environments
where you would like to use
[BigQuery](https://cloud.google.com/bigquery).

When querying your BigQuery data source, Chalk will push down filters on top of your
queries to optimize the amount of data read from your tables. For larger queries, rather than
interpolating values directly in the SQL string for the query, which has length limits in
BigQuery, Chalk will use a table to temporarily hold the values against which to query.
As such, we require `bigquery.tables.create` and `bigquery.jobs.create` permissions to
create and use these temporary tables.

The temporary project & dataset is used for scratch tables during unload operations and filter pushdown.
It's recommended to configure the temporary table dataset with a TTL (Time To Live) on all tables,
such as 6 hours, which should be bounded by your maximum job lifetime to ensure automatic cleanup of
temporary resources.


## Integrations Setup

After configuring your BigQuery integration with the [GCP integration](/docs/gcp), define your data sources in Python:

```py
from chalk.sql import BigQuerySource

risk = BigQuerySource(name="RISK")
marketing = BigQuerySource(name="MARKETING")
```

You can then reference them in [SQL file resolvers](/docs/sql-resolvers) using the `name` parameter. For example, to query from the `RISK` source:

```sql
-- type: online
-- resolves: User
-- source: RISK
SELECT id, credit_score FROM users
```

And to query from the `MARKETING` source:

```sql
-- type: online
-- resolves: User
-- source: MARKETING
SELECT id, email, campaign_status FROM users
```
