---
title: Windowed
description: Define features as aggregations of data over sliding time ranges.
published: true
---

Windowed features are features defined over time ranges. For example, you can use windowed
features to count the number of login attempts made by a user over the past 10 minutes, or
to track the largest purchase amount a cardholder has made in the past 30 days.

## Feature definition

Here is an example of a [windowed](/api-docs/#windowed) feature representing the number of
failed logins in the last 10 minutes, 30 minutes, and 1 day:

```py
@features
class User:
    id: int
    num_failed_logins: Windowed[int] = windowed(
        "10m",
        "30m",
        "1d",
        max_staleness="10m",
        default=0,
        owner="trust-and-safety",
    )
```

Windowed features support much of the same functionality as a normal feature.  Like features for mapping resolvers,
windowed features are most often used alongside [max_staleness](/api-docs#windowed.max_staleness) and
[etl_offline_to_online](/api-docs#windowed.etl_offline_to_online) to allow the features to be sent to online store and
offline store after each window period.  Windowed features often use [default](/api-docs#windowed.default) to set a
default value to return when there are no messages within a time period.

A windowed feature can be referenced in a query or a resolver in the following, equivalent ways. Each
column below shows the possible syntax variants for a given time window.

```py
# Note: The last value for each list is the time converted to seconds
User.num_failed_logins("**10m**")    User.num_failed_logins("**1d**")       User.num_failed_logins("**1h30m**")
User.num_failed_logins["**10m**"]    User.num_failed_logins["**1d**"]       User.num_failed_logins["**1h30m**"]
User.num_failed_logins_10m       User.num_failed_logins_1d          User.num_failed_logins_1h30m
User.num_failed_logins__10m__    User.num_failed_logins__1d__       User.num_failed_logins__1h30m__
User.num_failed_logins__600__    User.num_failed_logins__86400__    User.num_failed_logins__5400__
```

### Input to other resolvers

Windowed features can be inputs to resolvers:

```python
@online
def account_under_attack(
    failed_logins_30m: User.num_failed_logins('30m'),
    failed_logins_1d: User.num_failed_logins('1d')
) -> ...:
    return failed_logins_30m > 10 or failed_logins_1d > 100
```


## Windowed aggregation for performance

Windowed features are typically computed using either raw data or pre-aggregated data. Raw data has the most accuracy,
but can be slow if you request longer time windows or large volumes of data. Some systems improve performance by serving
features from pre-aggregated batch data. Pre-aggregated data mitigates the performance issue by reducing the number of
data points needed, but prevents your application from accessing the newest data entering your system.

Chalk balances accuracy and performance by combining both approaches. We aggregate historical data while continuously
updating as new data arrives. To have Chalk aggregate your data, pass
[materialization](/api-docs#windowed.materialization) to your windowed feature and use `bucket_duration` to set the size
of each aggregated time window:

```python
@features
class User:
    id: int
    transactions: DataFrame[transactions],
    total_transaction_amount: Windowed[int] = windowed(
        "10d",
        "90d",
        materialization={"bucket_duration": "1d"},
	 expression=_.transactions[_.amount].sum(),
    )
```

Because this code shows a `bucket_duration` of 1 day, Chalk will aggregate transaction data into 1 day buckets. Chalk
will then use these buckets to serve `total_transaction_amount` for the past 30 days and 90 days. As new data arrives,
the relevant bucket is modified to include the data.

### How aggregation works
When you pass `materialization` with `bucket_duration`, the Chalk online store uses the bucket duration to determine how
to aggregate and store your data internally. Rather than computing your feature from raw data, Chalk will instead
compute the feature using a fixed number of data points, which we call buckets. The number of buckets is determined by
your longest time window divided by your bucket duration. For example, if your time window is 90 days and your bucket
duration is 1 day, you would have 90 buckets. If your bucket duration is set to 1 minute, you would instead have 129,600
buckets.

Chalk uses the buckets corresponding to the requested time window to serve windowed features. Over time, the oldest
buckets are removed from consideration. Buckets are continually updated as new data arrives, ensuring the feature
operates on fresh data.

## Windowed streaming
To learn more about using windowed features with streaming data sources, see our
documentation on [windowed streaming](/docs/windowed-streaming).