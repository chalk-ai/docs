---
title: Snowflake Setup Requirements
description: Setting up Snowflake as your offline store.
published: true
---

import { ServiceDiagramSwitcher } from '@/components/ArchitectureDiagram'

---

Chalk's feature platform enables
machine learning teams to focus on building the unique products and models
that make their business stand out. Chalk provides a feature store so that
you can deploy production machine learning pipelines for real time data
in minutes.

Chalk is both a framework and a platform — developers can write code
using familiar Python packages, and deploy their feature and data pipeline definitions
to Chalk’s platform. In the Customer Cloud deployment, Chalk runs &
administers its platform on the customer’s cloud account. Chalk's managed
infrastructure then executes the customer defined pipelines to compute
[feature](/docs/features)
data for machine learning applications. Chalk then serves this data
back to customer applications for online inference and to customer
data teams for training set generation.

---

## Architecture

<ServiceDiagramSwitcher default_option={"AWS"} hideSwitch />

---

## Database Setup

To use Snowflake as your offline store, we require
a warehouse, a database, a schema within that database, and a user with a role that
has `OWNER` on that database. To provision all of these, you can run the following
commands in a Snowflake worksheet or console. To generate your SSH key pair you can run
the following:

```bash
# Generate the key pair
ssh-keygen -t rsa -b 4096 -m PEM -f snowflake_key

# Get the public key in the right format (remove header/footer and newlines)
grep -v "BEGIN PUBLIC KEY" snowflake_key.pub | grep -v "END PUBLIC KEY" | tr -d '\n'
```

Then, in SnowSQL, run the following commands, replacing the variables at the top:

```sql
-- input variables (feel free to change these)
SET WAREHOUSE_NAME='CHALK_WAREHOUSE';
SET WAREHOUSE_SIZE='XSMALL';
SET ROLE_NAME='CHALK_ROLE';
SET USER_NAME='CHALK_USER';
SET DB_NAME='CHALK';
SET SCHEMA_NAME='OFFLINE_STORE';

-- Create the database + schema + warehouse
CREATE DATABASE IF NOT EXISTS IDENTIFIER($DB_NAME);
USE DATABASE IDENTIFIER($DB_NAME);
CREATE SCHEMA IF NOT EXISTS IDENTIFIER($SCHEMA_NAME);
CREATE WAREHOUSE IF NOT EXISTS IDENTIFIER($WAREHOUSE_NAME) WITH WAREHOUSE_SIZE=$WAREHOUSE_SIZE;

-- Create a role for Chalk
CREATE ROLE IF NOT EXISTS IDENTIFIER($ROLE_NAME);
GRANT OWNERSHIP ON DATABASE IDENTIFIER($DB_NAME) TO ROLE IDENTIFIER($ROLE_NAME);
GRANT USAGE ON WAREHOUSE IDENTIFIER($WAREHOUSE_NAME) TO ROLE IDENTIFIER($ROLE_NAME);

-- Create a user for Chalk
CREATE USER IF NOT EXISTS IDENTIFIER($USER_NAME)
    RSA_PUBLIC_KEY=`<your-public-key-here-without-BEGIN/END-lines>`
    DEFAULT_ROLE=IDENTIFIER($ROLE_NAME)
    DEFAULT_WAREHOUSE=IDENTIFIER($WAREHOUSE_NAME)
    DEFAULT_NAMESPACE=IDENTIFIER(concat($DB_NAME, '.', $SCHEMA_NAME));

-- derived variables
SET QUALIFIED_SCHEMA_NAME=concat($DB_NAME, '.', $SCHEMA_NAME);

-- Allow Chalk to create storage integrations for bulk loads from cloud object storage
GRANT CREATE INTEGRATION ON ACCOUNT TO IDENTIFIER($ROLE_NAME);

-- Allow Chalk to create internal/external stages for bulk loading
GRANT CREATE STAGE ON SCHEMA IDENTIFIER($QUALIFIED_SCHEMA_NAME) TO IDENTIFIER($ROLE_NAME);

-- Grant Chalk owner on the db/schema and usage on the warehouse
GRANT OWNERSHIP ON SCHEMA IDENTIFIER($QUALIFIED_SCHEMA_NAME) TO IDENTIFIER($ROLE_NAME) REVOKE CURRENT GRANTS;
GRANT USAGE ON WAREHOUSE IDENTIFIER($WAREHOUSE_NAME) TO IDENTIFIER($ROLE_NAME);
GRANT OWNERSHIP ON DATABASE IDENTIFIER($DB_NAME) TO IDENTIFIER($ROLE_NAME);

-- Grant the Chalk role to the Chalk user
GRANT ROLE IDENTIFIER($ROLE_NAME) TO USER IDENTIFIER($USER_NAME);
```

Please share:

- The `USER_NAME` and RSA private key with us securely via an encrypted message following [using GPG](/docs/public-key).
- The `WAREHOUSE_NAME`, `DB_NAME`, `SCHEMA_NAME`, and `ROLE_NAME` so that we can configure the Chalk platform to use them.
- Your Snowflake account name (`select current_account_name();`) and organization name (`select current_organization_name();`).

---

## Storage Integration Setup

Once you have created the warehouse, database, schema, user, and role, the next step
is to create storage integration(s).

The storage integration will create an IAM entity
along with allowed or blocked storage locations that will allow Chalk to securely load
and unload data from the offline store.

### Prerequisites

Before setting up the storage integration, ensure you have:

- **AWS Access**: Use the `IAMFullAccess` AWS managed policy, or a custom IAM policy with permissions for `iam:CreatePolicy`, `iam:CreateRole`, `iam:AttachRolePolicy`, and `iam:UpdateAssumeRolePolicy`
- **Snowflake Access**: Use the `ACCOUNTADMIN` role, or a custom role with `CREATE DATABASE`, `CREATE WAREHOUSE`, `CREATE INTEGRATION`, and `SECURITYADMIN` privileges (note: only `ACCOUNTADMIN` can initially grant the `CREATE INTEGRATION` privilege)
- **Required Information**:
  - **AWS Account ID**: The AWS account ID where your Chalk environment is deployed. You should have this from your Chalk deployment, or Chalk can provide it.
  - **S3 Bucket Name**: Standard naming is `chalk-{organization}-data-bucket`. If this bucket does not exist or uses a different name, contact Chalk for clarification. Note that `{organization}` is a placeholder that should be replaced with the identifiers used for your implementation. 
  - **Snowflake Role Name**: The role name you defined in the Database Setup step (above), typically `CHALK_ROLE`

---

### Step 1: Create AWS IAM Policy

This policy grants Snowflake the minimum permissions needed to read and write objects to your S3 bucket.

**Actions:**
1. Navigate to AWS IAM → Policies
2. Create a new policy named `chalk-{organization}-offline-store-access-policy`
3. Paste the following JSON policy (replacing `chalk-{organization}-data-bucket` with your actual bucket name):

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
              "s3:PutObject",
              "s3:GetObject",
              "s3:GetObjectVersion",
              "s3:DeleteObject",
              "s3:DeleteObjectVersion"
            ],
            "Resource": "arn:aws:s3:::chalk-{organization}-data-bucket/*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:ListBucket",
                "s3:GetBucketLocation"
            ],
            "Resource": "arn:aws:s3:::chalk-{organization}-data-bucket",
            "Condition": {
                "StringLike": {
                    "s3:prefix": [
                        "*"
                    ]
                }
            }
        }
    ]
}
```

**Policy Permissions Explained:**
- `s3:*Object*`: Allows reading, writing, and deleting objects in the bucket
- `s3:ListBucket`: Allows listing the bucket contents
- `s3:GetBucketLocation`: Required by Snowflake for S3 operations

---

### Step 2: Create AWS IAM Role

This role will be assumed by Snowflake to access the S3 bucket.

**Actions:**
1. Navigate to AWS IAM → Roles
2. Create a new role named `chalk-{organization}-offline-store-access-role`
3. Set the trust relationship with the following **initial placeholder** policy (you will update this in Step 4 with actual Snowflake credentials):

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "sts:AssumeRole",
            "Principal": {
                "AWS": "<AWS_ACCOUNT_ID>"
            },
            "Condition": {
                "StringEquals": {
                    "sts:ExternalId": "0000"
                }
            }
        }
    ]
}
```

**Important**: Replace `<AWS_ACCOUNT_ID>` with your AWS account ID where the Chalk environment is deployed. The `"0000"` is a temporary placeholder external ID — you will update both the Principal and ExternalId values in Step 4 after creating the Snowflake storage integration and obtaining the actual Snowflake IAM user ARN and external ID.

4. Attach the IAM policy created in Step 1 to this role

---

### Step 3: Create Snowflake Storage Integration

This creates the storage integration object in Snowflake that links to the AWS role and S3 bucket.

**Actions:**
1. Connect to your Snowflake account
2. Execute the following SQL commands (replace placeholders with actual values):

```sql
-- Create the storage integration pointing to your AWS S3 bucket and IAM role
CREATE STORAGE INTEGRATION "s3-integration-chalk-{organization}-data-bucket"
TYPE = EXTERNAL_STAGE
STORAGE_PROVIDER='s3'
STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::<your-aws-account-id>:role/chalk-{organization}-offline-store-access-role'
ENABLED = true
STORAGE_ALLOWED_LOCATIONS = ('s3://chalk-{organization}-data-bucket/');

-- Grant usage permissions to the Chalk role
GRANT USAGE ON INTEGRATION "s3-integration-chalk-{organization}-data-bucket" TO ROLE "CHALK_ROLE";

-- Verify the integration was created successfully and retrieve Snowflake credentials
DESCRIBE INTEGRATION "s3-integration-chalk-{organization}-data-bucket";
```

3. From the `DESCRIBE INTEGRATION` output, record the following values:
   - `STORAGE_AWS_IAM_USER_ARN`
   - `STORAGE_AWS_ROLE_ARN`
   - `STORAGE_AWS_EXTERNAL_ID`

You will need these values for Step 4.

---

### Step 4: Update IAM Role Trust Policy with Snowflake Credentials

This step completes the trust relationship between Snowflake and AWS by updating the IAM role's trust policy with the actual Snowflake credentials obtained from Step 3.

**Actions:**
1. Navigate to AWS IAM → Roles
2. Select the role `chalk-{organization}-offline-store-access-role` created in Step 2
3. Click the "Trust relationships" tab
4. Click "Edit trust policy"
5. Replace the placeholder values from Step 2 with the actual values from Step 3's `DESCRIBE INTEGRATION` output:
   - Replace `<AWS_ACCOUNT_ID>` with the actual `STORAGE_AWS_IAM_USER_ARN`
   - Replace `"0000"` with the actual `STORAGE_AWS_EXTERNAL_ID`

6. Your updated trust policy should look like this:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "sts:AssumeRole",
            "Principal": {
                "AWS": "<STORAGE_AWS_IAM_USER_ARN>"
            },
            "Condition": {
                "StringEquals": {
                    "sts:ExternalId": "<STORAGE_AWS_EXTERNAL_ID>"
                }
            }
        }
    ]
}
```

7. Save the updated trust policy

**Expected Outcome:**
- IAM role trust policy now contains Snowflake's actual IAM user ARN and external ID
- Snowflake can now successfully assume the AWS role to access the S3 bucket
- Trust relationship is fully configured for secure cross-account access

---

### Environment Variables Configuration

After completing the storage integration setup, configure the following environment variables through the Chalk UI to enable offline store persistence logging and feature value tracking:

**To add environment variables:**
1. Navigate to **Settings** → **Variables**
2. Add each of the following key-value pairs:

| Key | Value |
|-----|-------|
| `CHALK_PERSIST_TO_OFFLINE_STORE_QUERY_LOG` | `1` |
| `CHALK_PLANNER_PERSIST_VALUES_OFFLINE_STORE` | `1` |
| `CHALK_PLANNER_PERSIST_VALUES_PARQUET` | `1` |

These variables enable:
- Query logging for offline store operations
- Persistence of feature values to the offline store
- Parquet file format support for offline data

---

### Storage Integration Configuration

After setting up the storage integration and environment variables, configure the storage integration name in the Chalk UI:

**To configure the storage integration:**
1. Navigate to **Settings** → **Shared Resources** → **Background Persistence** → **General Configuration** → **Advanced**
2. Enter the Snowflake Storage Integration Name in the provided field (e.g., `s3-integration-chalk-{organization}-data-bucket`)
3. Click **Save and Apply Changes**

**Note:** Clicking **Save and Apply Changes** will re-deploy Background Persistence workers. Please use due caution when deploying resources.

---

### Troubleshooting

**Issue: "Access Denied" when querying data in Snowflake**
- Verify the AWS role ARN in the storage integration matches your actual IAM role
- Confirm the IAM policy is attached to the AWS role
- Check that the S3 bucket names in both AWS and Snowflake configurations match exactly
- Verify the trust policy has been updated with the correct `STORAGE_AWS_IAM_USER_ARN` and `STORAGE_AWS_EXTERNAL_ID`

**Issue: DESCRIBE INTEGRATION returns an error**
- Ensure you're connected to Snowflake with admin or equivalent privileges
- Verify the integration name is spelled correctly
- Check that the role has USAGE permissions on the integration

---

### Next Steps

After completing this setup:

1. Share the following values with Chalk:
   - Storage Integration Name (e.g., `s3-integration-chalk-{organization}-data-bucket`)
   - `STORAGE_AWS_IAM_USER_ARN`
   - `STORAGE_AWS_ROLE_ARN`
   - `STORAGE_AWS_EXTERNAL_ID`
   - AWS Account ID used
   - S3 bucket name

Chalk will use these values to configure your offline store in the platform.
